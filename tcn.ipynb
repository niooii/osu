{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33842c3f-f319-4081-b730-b875c380cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osu! path: None/../Local/osu!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import osu.dataset as dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3282829-4a26-4e8a-b7f8-d82cf20becaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from saved\n",
    "\n",
    "# mrekk glob\n",
    "xs = np.load(f'.datasets/xs_2225_12ms.npy')\n",
    "ys = np.load(f'.datasets/ys_2225_12ms.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0dd2ef6-cf2e-4cc8-9dbf-3d92e39071d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b91498ce-58d8-4b07-8a31-795b992ce925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import terminal_size\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "\n",
    "import osu.dataset as dataset\n",
    "from models.annealer import Annealer\n",
    "from models.base import OsuModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "\n",
    "# a causal convolutional layer that preserves the length of the original sequence\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, start_offset=0, **kwargs):\n",
    "        \"\"\"\n",
    "        start_offset is the time index where the kernel starts at. By default it will start\n",
    "        at time index 0, and since CausalConv1d's sliding kernel is left aligned, it will use padding\n",
    "        on the left. If start_offset > 0, then padding will be added appropriately on the right side, and\n",
    "        subtracted from the left, as any start_offset value preserves the original output shape of the layer. \n",
    "        Think of it as a way to add a small lookahead window. \n",
    "\n",
    "        start_offset must be strictly < kernel_size\n",
    "        \n",
    "        [a b c d e f g h]\n",
    "        -> pad (lookahead = 0, k = 3) ->\n",
    "        [0 0 a]b c d e f g h\n",
    "         0[0 a b]c d e f g h\n",
    "         0 0[a b c]d e f g h\n",
    "\n",
    "        or pad (lookahead = 2, k = 3) ->\n",
    "        [a b c]d e f g h 0 0\n",
    "         a[b c d]e f g h 0 0\n",
    "         a b[c d e] f g h 0 0\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        p = (kernel_size - 1) * dilation\n",
    "        self.lpad = max(p - start_offset, 0)\n",
    "        self.rpad = start_offset\n",
    "        self.dilation = dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              dilation=dilation, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.lpad, self.rpad))\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class CausalTCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, layers, lookahead_layers=0, lookahead_mode=\"full\"):\n",
    "        \"\"\"\n",
    "        layers is a tuple of (n1, n2, n3...)\n",
    "        where each n is a number of channels, and constructs layers:\n",
    "        (in_channels, n1)\n",
    "        (n1, n2)\n",
    "        (n2, n3)\n",
    "        ...\n",
    "        (ni, out_channels)\n",
    "\n",
    "        when these layers are applied, their dilation increases by a factor of two. \n",
    "        \n",
    "        the amount of timesteps of future context the model has acces to is determined by\n",
    "        2 ^ lookahead_layers               if lookahead_mode = full \n",
    "        max(2 ^ (lookahead_layers - 1), 1) if lookahead_mode = centered \n",
    "\n",
    "        full lookahead mode effectively maps a seq to a seq of the same length, \n",
    "        where each element in the new seq has context about the future timesteps.\n",
    "\n",
    "        centered lookahead mode maps a seq to a seq of the same length, \n",
    "        where each element in the new seq has context about both the past and the future. \n",
    "\n",
    "        lookahead_layers must be < len(layers).\n",
    "        \n",
    "        after the amount of requested lookahead layers have been applied, the dilation will reset to 1, and then\n",
    "        increase accordingly for the following causal layers. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = in_channels\n",
    "        self.output = out_channels\n",
    "\n",
    "        self.conv_layers = []\n",
    "\n",
    "        channels = [in_channels, *layers, out_channels]\n",
    "        \n",
    "        for i in range(len(channels) - 1):\n",
    "            in_c = channels[i]\n",
    "            out_c = channels[i+1]\n",
    "            if i < lookahead_layers:\n",
    "                self.conv_layers.append(\n",
    "                    CausalConv1d(in_c, out_c, kernel_size=3, dilation=2 ** i, start_offset=(2 if lookahead_mode == \"full\" else 1))\n",
    "                )\n",
    "            else:\n",
    "                self.conv_layers.append(\n",
    "                    CausalConv1d(in_c, out_c, kernel_size=3, dilation=2 ** (i - lookahead_layers))\n",
    "                )\n",
    "                \n",
    "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        \"\"\"\n",
    "        sequence is of shape (B, T, F) where \n",
    "        B = batch size\n",
    "        T = sequence length\n",
    "        F = feature count\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = sequence.shape\n",
    "\n",
    "        map = sequence.transpose(1, 2)  # (B, F, T)\n",
    "\n",
    "        out = map\n",
    "\n",
    "        # TODO! pad with default frame\n",
    "        for layer in self.conv_layers:\n",
    "            # out = F.pad(out, (layer.dilation, layer.dilation))\n",
    "            out = layer(out)\n",
    "\n",
    "            if layer != self.conv_layers[-1]:\n",
    "                out = self.relu(out)\n",
    "                \n",
    "        return out.transpose(1, 2)  # transpose back to (B, T, F')\n",
    "\n",
    "class ReplayGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_dim=32,\n",
    "        tcn_layers=(64, 128, 196, 128, 64),\n",
    "        lookahead_layers=0, \n",
    "        lookahead_mode=\"full\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tcn = CausalTCN(\n",
    "            len(dataset.INPUT_FEATURES), \n",
    "            2, \n",
    "            layers=tcn_layers, \n",
    "            lookahead_layers=lookahead_layers, \n",
    "            lookahead_mode=lookahead_mode\n",
    "        )\n",
    "\n",
    "    def forward(self, map_features, noise):\n",
    "        return self.tcn(map_features)\n",
    "\n",
    "class ReplayCritic(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size=128, lstm_layers=2, dropout=0.1, bi_dir=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bi_dir = bi_dir\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size + 2,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bi_dir,\n",
    "        )\n",
    "\n",
    "        mlp_in_dim = lstm_hidden_size * (2 if bi_dir else 1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_in_dim, mlp_in_dim // 2),\n",
    "            nn.LayerNorm(mlp_in_dim // 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(mlp_in_dim // 2, 1),\n",
    "        )\n",
    "\n",
    "    # TODO try with keys also? prob not gonna end well\n",
    "    def forward(self, map_features, positions):\n",
    "        # map_features: (B, T, feat_dim), positions: (B, T, 2),\n",
    "        # T is chunk length\n",
    "\n",
    "        return torch.zeros((map_features.shape[0]), requires_grad=True)\n",
    "        # TODO\n",
    "        # x = torch.cat([map_features, positions], dim=-1)  # (B, T, feat_dim+2)\n",
    "        # # _, (h_n, _) = self.lstm(x)\n",
    "        # # h = h_n[-1]  # (B, lstm_hidden_dim)\n",
    "        # # TODO! don't pool over time why we losing temporal info\n",
    "\n",
    "        # # score = self.mlp(h).squeeze(-1)  # (B,)\n",
    "\n",
    "        # h_out, _ = self.lstm(x)      # (B, T, H)\n",
    "        # h = h_out.mean(dim=1)\n",
    "        # score = self.mlp(h).squeeze(-1)\n",
    "        # return score\n",
    "\n",
    "\n",
    "def gradient_penalty(critic, windowed, real_pos, fake_pos, device, lambda_gp=10.0):\n",
    "    B = real_pos.shape[0]\n",
    "    # alpha (B,1,1) will broadcast across (T,2)\n",
    "    alpha = torch.rand(B, 1, 1, device=device)\n",
    "\n",
    "    # interpolation in position space\n",
    "    # (B, T, 2)\n",
    "    x = (alpha * real_pos + (1.0 - alpha) * fake_pos).requires_grad_(True)\n",
    "\n",
    "    # (B,)\n",
    "    C_x = critic(windowed, x)\n",
    "\n",
    "    # compute gradients of outputs wrt interpolated positions\n",
    "    # (this works since the gradient distributes)\n",
    "    # (B, T, 2)\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=C_x.sum(),\n",
    "        inputs=x,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    # flatten per-sample gradients and compute L2 norm per sample\n",
    "    # (B,)\n",
    "    grad_norm = grads.reshape(B, -1).norm(2, dim=1)\n",
    "\n",
    "    gp = ((grad_norm - 1.0) ** 2).mean() * lambda_gp\n",
    "\n",
    "    del grads, grad_norm, C_x, x\n",
    "\n",
    "    return gp\n",
    "\n",
    "# an implementation of a WGAN with a gp critic\n",
    "class OsuReplayWGAN(OsuModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size=64,\n",
    "        device=None,\n",
    "        noise_dim=32,\n",
    "        critic_steps=3,\n",
    "        lambda_gp=10.0,\n",
    "        lambda_pos=1.0,\n",
    "        lambda_adv_annealer=None,\n",
    "        tcn_layers=(64, 128, 196, 196, 128, 96, 96, 32),\n",
    "        lookahead_layers=5,\n",
    "        lookahead_mode=\"full\",\n",
    "        lr_g=1e-4,\n",
    "        lr_c=1e-4,\n",
    "        betas_gan=(0.5, 0.9),\n",
    "        use_gp=True,\n",
    "        compile=False,\n",
    "    ):\n",
    "        self.noise_dim = noise_dim\n",
    "        self.critic_steps = critic_steps\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.lr_g = lr_g\n",
    "        self.lr_c = lr_c\n",
    "        self.betas_gan = betas_gan\n",
    "        self.lambda_pos = lambda_pos\n",
    "        self.use_gp = use_gp\n",
    "        self.lambda_adv_annealer = lambda_adv_annealer or Annealer(\n",
    "            total_steps=20, range=(0.0, 1.0), cyclical=False\n",
    "        )\n",
    "        self.tcn_layers=tcn_layers\n",
    "        self.lookahead_layers=lookahead_layers\n",
    "        self.lookahead_mode=lookahead_mode\n",
    "\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            compile=compile,\n",
    "        )\n",
    "\n",
    "    def _initialize_models(self, **kwargs):\n",
    "        self.generator = ReplayGenerator(\n",
    "            noise_dim=self.noise_dim,\n",
    "            tcn_layers=self.tcn_layers,\n",
    "            lookahead_layers=self.lookahead_layers,\n",
    "            lookahead_mode=self.lookahead_mode\n",
    "        )\n",
    "\n",
    "        # windowed features per timestep dimension\n",
    "\n",
    "        # scores a play on realness\n",
    "        self.critic = ReplayCritic(\n",
    "            len(dataset.INPUT_FEATURES), \n",
    "            # self.input_size,\n",
    "            lstm_hidden_size=128, \n",
    "            lstm_layers=2, \n",
    "            dropout=0.1,\n",
    "            bi_dir=False\n",
    "        )\n",
    "\n",
    "        if self.use_gp:\n",
    "            print(\"using gp\")\n",
    "        else:\n",
    "            print(\"not using gp\")\n",
    "\n",
    "    def _initialize_optimizers(self):\n",
    "        self.opt_G = optim.AdamW(\n",
    "            self.generator.parameters(), lr=self.lr_g, betas=self.betas_gan\n",
    "        )\n",
    "        self.opt_C = optim.AdamW(\n",
    "            self.critic.parameters(), lr=self.lr_c, betas=self.betas_gan\n",
    "        )\n",
    "\n",
    "    def _get_state_dict(self):\n",
    "        return {\n",
    "            \"critic\": self.critic.state_dict(),\n",
    "            \"generator\": self.generator.state_dict(),\n",
    "            \"noise_dim\": self.noise_dim,\n",
    "        }\n",
    "\n",
    "    def _load_state_dict(self, checkpoint):\n",
    "        if \"generator\" in checkpoint:\n",
    "            self.generator.load_state_dict(checkpoint[\"generator\"])\n",
    "        else:\n",
    "            print(\"No generator weights found, not loading generator\")\n",
    "\n",
    "        if \"critic\" in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint[\"critic\"])\n",
    "        else:\n",
    "            print(\"No critic weights found, not loading critic\")\n",
    "\n",
    "    def _train_epoch(self, epoch, total_epochs, **kwargs):\n",
    "        epoch_total_loss = 0.0\n",
    "        epoch_recon_loss = 0.0\n",
    "        epoch_adv_loss = 0.0\n",
    "        epoch_G_loss = 0.0\n",
    "        epoch_C_loss = 0.0\n",
    "        epoch_wass_dist = 0.0\n",
    "\n",
    "        device = self.device or torch.device(\"cpu\")\n",
    "\n",
    "        p_real_mean = 0.0\n",
    "        p_fake_mean = 0.0\n",
    "        p_wass = 0.0\n",
    "        for j, (batch_x, batch_y_pos) in enumerate(self.train_loader):\n",
    "            status_prefix = f\"{j}/{len(self.train_loader)} (λ_adv: {self.lambda_adv_annealer.current():.5f}, r: {p_real_mean:.4f}, f: {p_fake_mean:.4f}, w: {p_wass:.4f}) \"\n",
    "            self._set_custom_train_status(status_prefix)\n",
    "\n",
    "            p_real_mean = 0.0\n",
    "            p_fake_mean = 0.0\n",
    "            p_wass = 0.0\n",
    "\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y_pos = batch_y_pos.to(device)\n",
    "\n",
    "            # BATCH SIZE\n",
    "            B = batch_x.shape[0]\n",
    "\n",
    "            critic_loss_accum = 0.0\n",
    "\n",
    "            # train the critic for n steps per epoch\n",
    "            for i in range(self.critic_steps):\n",
    "                self._set_custom_train_status(\n",
    "                    status_prefix + f\"Critic: {i}/{self.critic_steps}\"\n",
    "                )\n",
    "\n",
    "                # sample xi noise for generator\n",
    "                # (B, noise_dim)\n",
    "                xi_c = torch.randn(B, self.noise_dim, device=device)\n",
    "\n",
    "                # (B, T, 2)\n",
    "                fake_pos = self.generator(batch_x, xi_c).detach()\n",
    "\n",
    "                # (B,)\n",
    "                real_score = self.critic(batch_x, batch_y_pos)\n",
    "                # (B,)\n",
    "                fake_score = self.critic(batch_x, fake_pos)\n",
    "\n",
    "                real_mean = real_score.mean().item()\n",
    "                fake_mean = fake_score.mean().item()\n",
    "                wass = real_mean - fake_mean\n",
    "\n",
    "                p_real_mean += real_mean\n",
    "                p_fake_mean += fake_mean\n",
    "                p_wass += wass\n",
    "\n",
    "                epoch_wass_dist += wass\n",
    "\n",
    "                # lambda term is already multiplied in here\n",
    "                if self.use_gp:\n",
    "                    gp = gradient_penalty(\n",
    "                    self.critic,\n",
    "                    batch_x,\n",
    "                    real_pos=batch_y_pos,\n",
    "                    fake_pos=fake_pos,\n",
    "                    device=device,\n",
    "                    lambda_gp=self.lambda_gp,\n",
    "                )\n",
    "                else:\n",
    "                    gp = 0\n",
    "\n",
    "                # total wgan-gp critic loss\n",
    "                loss = -(real_score.mean() - fake_score.mean()) + gp\n",
    "\n",
    "                self.opt_C.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.critic.parameters(), max_norm=1.0)\n",
    "                self.opt_C.step()\n",
    "\n",
    "                # weight clipping bc i hate gp\n",
    "                # clip_value = 0.6\n",
    "                # for p in self.critic.parameters():\n",
    "                #     p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "                critic_loss_accum += loss.item()\n",
    "\n",
    "            p_real_mean /= self.critic_steps\n",
    "            p_fake_mean /= self.critic_steps\n",
    "            p_wass /= self.critic_steps\n",
    "\n",
    "            # train the generator now\n",
    "            self._set_custom_train_status(status_prefix + f\"Generator\")\n",
    "\n",
    "            xi = torch.randn(B, self.noise_dim, device=device)\n",
    "            fake = self.generator(batch_x, xi)\n",
    "\n",
    "            # TODO! add consistency loss prob\n",
    "            # or mse is good enough idk lol\n",
    "            adv_loss = self.lambda_adv_annealer.current() * (-self.critic(batch_x, fake).mean())\n",
    "            pos_loss = self.lambda_pos * F.smooth_l1_loss(\n",
    "                fake, batch_y_pos, reduction=\"mean\"\n",
    "            )\n",
    "\n",
    "            gen_loss = adv_loss + pos_loss\n",
    "\n",
    "            self.opt_G.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.generator.parameters(), max_norm=1.0)\n",
    "            self.opt_G.step()\n",
    "\n",
    "            epoch_C_loss += critic_loss_accum / max(1, self.critic_steps)\n",
    "            epoch_G_loss += gen_loss.item()\n",
    "            epoch_recon_loss += pos_loss.item()\n",
    "            epoch_adv_loss += adv_loss.item()\n",
    "\n",
    "        self.lambda_adv_annealer.step()\n",
    "\n",
    "        nb = len(self.train_loader)\n",
    "        return {\n",
    "            \"recon\": epoch_recon_loss / nb,\n",
    "            \"adv\": epoch_adv_loss / nb,\n",
    "            \"g\": epoch_G_loss / nb,\n",
    "            \"c\": epoch_C_loss / nb,\n",
    "            \"wass\": epoch_wass_dist / (nb * self.critic_steps)\n",
    "        }\n",
    "\n",
    "    def generate(self, beatmap_data, **kwargs):\n",
    "        self._set_eval_mode()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            beatmap_tensor = torch.FloatTensor(beatmap_data).to(self.device)\n",
    "\n",
    "            batch_size = beatmap_tensor.shape[0]\n",
    "\n",
    "            noise = torch.randn(batch_size, self.noise_dim, device=self.device)\n",
    "\n",
    "            pos = self.generator(beatmap_tensor, noise)\n",
    "\n",
    "        return pos.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b7c96cc4-e904-40fe-bcf2-e3c299a2f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using gp\n",
      "ReplayWGAN initialized on cuda\n",
      "critic parameters: 212737\n",
      "generator parameters: 276226\n",
      "Total parameters: 488963\n",
      "Data loaded: 10893 training samples, 2724 test samples\n"
     ]
    }
   ],
   "source": [
    "tcn = OsuReplayWGAN(\n",
    "    batch_size=128,\n",
    "    device=None,\n",
    "    noise_dim=32,\n",
    "    critic_steps=3,\n",
    "    lambda_gp=10.0,\n",
    "    lambda_pos=1.0,\n",
    "    lambda_adv_annealer=None,\n",
    "    tcn_layers=(64, 128, 128, 128, 128, 96, 96, 96, 32),\n",
    "    lookahead_layers=6,\n",
    "    lookahead_mode=\"full\",\n",
    "    lr_g=1e-4,\n",
    "    lr_c=1e-4,\n",
    "    betas_gan=(0.5, 0.9),\n",
    "    use_gp=False,\n",
    "    compile=False\n",
    ")\n",
    "tcn.load_data(xs, ys)\n",
    "model = tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6f7ae118-d722-43ce-a50d-d0af3a0e2742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a012c4d3fd348a4b3ed2050ee5207e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[170]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtcn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/osu-nn/models/base.py:132\u001b[39m, in \u001b[36mOsuModel.train\u001b[39m\u001b[34m(self, epochs, save_every, save_dir, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_iterator:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_iterator.set_description(\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m + (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    130\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     epoch_losses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m loss_name, loss_value \u001b[38;5;129;01min\u001b[39;00m epoch_losses.items():\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m loss_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training_history:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[149]\u001b[39m\u001b[32m, line 426\u001b[39m, in \u001b[36mOsuReplayWGAN._train_epoch\u001b[39m\u001b[34m(self, epoch, total_epochs, **kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28mself\u001b[39m.opt_G.step()\n\u001b[32m    425\u001b[39m epoch_C_loss += critic_loss_accum / \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.critic_steps)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m epoch_G_loss += \u001b[43mgen_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m epoch_recon_loss += pos_loss.item()\n\u001b[32m    428\u001b[39m epoch_adv_loss += adv_loss.item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tcn.train(2000, save_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c749fe7a-8139-45db-a6e2-ff34aa0f61f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Turning Miniministop Hitoyasumi no Uta[Mokuyoubi]Gakusei no Uta into time series data: 100%|███████████████████| 1/1 [00:00<00:00, 54.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# test training results\n",
    "from osu.rulesets.mods import Mods\n",
    "import osu.rulesets.beatmap as bm\n",
    "import osu.dataset as dataset\n",
    "import torch\n",
    "\n",
    "test_name = 'miniministop'\n",
    "test_mods = Mods.HARD_ROCK \n",
    "test_map_path = f'assets/{test_name}_map.osu'\n",
    "test_song = f'assets/{test_name}_song.mp3'\n",
    "\n",
    "test_map = bm.load(test_map_path)\n",
    "test_map.apply_mods(test_mods)\n",
    "\n",
    "data = dataset.input_data(test_map)\n",
    "# no chunking for lstm based\n",
    "data = np.reshape(data.values, (-1, data.shape[0], len(dataset.INPUT_FEATURES)))\n",
    "data = torch.FloatTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "baa82fa3-f2df-49eb-8fef-e3e8f35fb2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096, 2)\n",
      "Generated replay data shape: (4096, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.1527412 ,  0.01476777,  0.        ,  0.        ],\n",
       "       [-0.15899178,  0.00659665,  0.        ,  0.        ],\n",
       "       [-0.15360594,  0.01104177,  0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.01216203, -0.00846693,  0.        ,  0.        ],\n",
       "       [-0.01295521, -0.00829178,  0.        ,  0.        ],\n",
       "       [-0.01260592, -0.01183941,  0.        ,  0.        ]],\n",
       "      shape=(4096, 4), dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_data = model.generate(data)\n",
    "print(replay_data.shape)\n",
    "    \n",
    "replay_data = np.concatenate(replay_data)\n",
    "replay_data = np.pad(replay_data, ((0, 0), (0, 2)), mode='constant', constant_values=0)\n",
    "if not os.path.exists('.generated'):\n",
    "    os.makedirs('.generated')\n",
    "    \n",
    "print(f\"Generated replay data shape: {replay_data.shape}\")\n",
    "replay_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6f4b7157-6a8e-44c7-a54f-6f16929de22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osu.preview.preview as preview\n",
    "\n",
    "preview.preview_replay_raw(replay_data[:, :4], test_map_path, test_mods, test_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814024b-ee86-4c35-9ac8-57696807b660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b052116-fd38-4ef6-805f-7de1e63632c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
